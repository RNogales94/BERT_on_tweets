{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Libreta4 - LSTM con Word Embeddings preentrenados.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joSanchez28/BERT_on_tweets/blob/master/Libreta4_LSTM_con_Word_Embeddings_preentrenados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWVPOSNSgt3e",
        "colab_type": "text"
      },
      "source": [
        "# LSTMs con Word Embeddings para clasificación de sentimientos\n",
        "\n",
        "En esta libreta creamos un modelo de forma sencilla con Keras usando unidades recurrentes LSTM de tipo bidireccional y lo entrenamos con nuestro conjunto de tweets.\n",
        "\n",
        "En primer lugar importamos los paquetes necesarios."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWg9UzpNgt3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
        "#Para la LSTM-CNN\n",
        "from tensorflow.keras.layers import Activation \n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
        "##\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.initializers import Constant\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogaYNJh-gt3h",
        "colab_type": "text"
      },
      "source": [
        "Parámetros para el modelo y el entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAxqIoOXgt3h",
        "colab_type": "code",
        "outputId": "b6cf2d17-8070-494b-9628-d40e396ebdca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Embedding\n",
        "#max_features = 20000 #Original\n",
        "max_features = 48000 #Fijado viendo que el nº de palabras que aparece al menos 5 veces en el conjunto de entrenamiento es 47193\n",
        "#maxlen = 100 #Original\n",
        "#maxlen = 150 #La que usé\n",
        "maxlen = 40\n",
        "#embedding_size = 128\n",
        "embedding_dim = 100 #Podría ser también 25, 50 o 200 (los que se pueden descargar)\n",
        "\n",
        "# Convolution\n",
        "kernel_size = 5\n",
        "filters = 64\n",
        "pool_size = 4\n",
        "\n",
        "# LSTM\n",
        "lstm_output_size = 70\n",
        "\n",
        "# Training\n",
        "batch_size = 30\n",
        "epochs = 20\n",
        "\n",
        "'''\n",
        "Note:\n",
        "batch_size is highly sensitive.\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nNote:\\nbatch_size is highly sensitive.\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2nn_Vkmgt3k",
        "colab_type": "text"
      },
      "source": [
        "## Carga de los word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZcfayDhgt3k",
        "colab_type": "code",
        "outputId": "26865346-dadb-46f1-bbcb-37d1aeb6fbbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4ML-Le_gt3n",
        "colab_type": "code",
        "outputId": "3dfd126f-b16d-49c2-85be-b635955b1955",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "word_emb_path = \"/content/drive/My Drive/WordEmbeddings/\"\n",
        "#word_emb_path = '../WordEmbeddings/'\n",
        "# first, build index mapping words in the embeddings set\n",
        "# to their embedding vector\n",
        "\n",
        "print('Indexing word vectors.')\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(word_emb_path + \"glove.twitter.27B.100d.txt\", encoding=\"utf8\") as f: #'glove.6B.100d.txt'\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, 'f', sep=' ')\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Indexing word vectors.\n",
            "Found 1193514 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klqvgwWKgt3p",
        "colab_type": "code",
        "outputId": "79bd9f90-f9e7-4d11-be7a-3903e544c7e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "embeddings_index['you']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7.3793e-02,  2.2958e-01,  1.6190e-01,  5.1383e-01, -1.3568e-01,\n",
              "        5.9524e-02,  5.7240e-01, -3.3930e-01,  1.0477e-01,  2.4796e-01,\n",
              "       -1.3659e-01, -3.7421e-01, -6.1651e+00, -3.6166e-01, -3.6804e-01,\n",
              "       -8.1314e-02, -3.3600e-02, -3.0373e-01, -4.0536e-01,  9.4863e-02,\n",
              "       -1.4260e-01, -2.3630e-01, -1.0712e-01,  2.4055e-01,  2.2325e-01,\n",
              "       -6.2564e-01,  1.9939e-01,  5.1398e-01,  4.9040e-01, -4.6308e-01,\n",
              "       -1.4342e-01,  1.9332e-02, -9.5564e-02,  2.5391e-01,  7.0189e-02,\n",
              "        1.9461e-01,  3.5724e-01,  2.4704e-01,  3.8155e-01, -2.3231e-01,\n",
              "       -9.9356e-01,  3.2767e-01,  3.0328e-01,  5.5577e-01,  5.8440e-01,\n",
              "       -2.2246e-01, -2.4206e-01, -7.4880e-01,  2.3144e-01, -5.3725e-03,\n",
              "       -3.1667e-01, -1.2560e-01,  4.0173e-01, -3.3374e-01,  9.1548e-01,\n",
              "        2.6268e-01, -6.8389e-01,  3.3916e-01,  1.7124e-01,  4.7471e-01,\n",
              "        3.8165e-01,  9.8252e-02, -4.3935e-01,  2.7527e-01,  2.3848e-01,\n",
              "       -3.7455e-02, -9.7668e-01, -8.1719e-03, -3.7798e-01,  2.1634e-01,\n",
              "        7.5920e-01,  1.7825e-01,  2.1407e-01, -6.5874e-01,  9.9135e-02,\n",
              "       -2.4406e-01, -8.9665e-03, -3.6250e-01, -8.7086e-01,  7.9953e-02,\n",
              "        1.8543e+00,  5.2843e-01, -4.0883e-01,  2.2817e-01,  3.2473e-01,\n",
              "        2.7017e-01, -5.3825e-01,  8.8920e-02, -1.5773e-01,  1.1811e-01,\n",
              "        2.7935e-01,  1.1127e-01, -6.0050e-02,  2.6238e-01, -1.8814e-01,\n",
              "        2.3596e-02, -4.3750e-01, -5.7185e-01,  5.6693e-01, -9.7415e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_QDq_9Igt3r",
        "colab_type": "text"
      },
      "source": [
        "## Carga de los conjuntos de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE1hMQjvgt3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cargamos los tres conjuntos de datos\n",
        "data_path = \"/content/drive/My Drive/Datos/\"\n",
        "#data_path = \"../Datos/\"\n",
        "df_train = pd.read_csv(data_path + \"train_set.csv\")\n",
        "df_val = pd.read_csv(data_path + \"val_set.csv\")\n",
        "df_test = pd.read_csv(data_path + \"test_set.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osBUGXV6gt3u",
        "colab_type": "text"
      },
      "source": [
        "## Preprocesado del conjunto de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVynRbC6gt3u",
        "colab_type": "text"
      },
      "source": [
        "Al igual que hicimos en la libreta 2 con el modelo BERT, sustituimos las URLs por la palabra URL y los nombres de usuario por la palabra USER. Además, esta vez quitamos todos los signos de puntuación y ponemos todo el texto en minúscula."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPh1hyxwgt3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Para detectar urls y sustituirlas por URL\n",
        "TEXT_URL = \"https?:\\S+|http?:\\S|www\\.\\S+|\\S+\\.(com|org|co|us|uk|net|gov|edu)\"\n",
        "# Para detectar nombres de usuario y sustituirlos por USER\n",
        "TEXT_USER = \"@\\S+\"\n",
        "# Para quitar signos de puntuación o caracteres extraños\n",
        "TEXT_CLEANING = \"[^A-Za-z0-9]+\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2LRRXtegt3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(text, stem=False):\n",
        "    text = re.sub(TEXT_URL,  'URL',    text)           # Cambiamos las URLs por la palabra 'URL'\n",
        "    text = re.sub(TEXT_USER,  'USER', text)           # Cambiamos los nombres de usuario por la palabra 'USER'\n",
        "    text = re.sub(r'\\s+', ' ',   text).strip()        # Eliminamos dobles espacios en blanco y los espacios en blanco al principio o al final\n",
        "    text = re.sub(TEXT_CLEANING, ' ', str(text).lower()) # Eliminamos signos de puntuación y caracteres no alfanuméricos y lo ponemos en minuscula\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSLIHxajgt3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.text = df_train.text.apply(lambda x: preprocess(x))\n",
        "df_val.text = df_val.text.apply(lambda x: preprocess(x))\n",
        "df_test.text = df_test.text.apply(lambda x: preprocess(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjxxWt9Ugt31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decode_map = {0: 0, 4: 1}\n",
        "def decode_sentiment(label):\n",
        "    return decode_map[int(label)]\n",
        "\n",
        "df_train.target = df_train.target.apply(lambda x: decode_sentiment(x))\n",
        "df_val.target = df_val.target.apply(lambda x: decode_sentiment(x))\n",
        "df_test.target = df_test.target.apply(lambda x: decode_sentiment(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOEJgx-Bgt33",
        "colab_type": "text"
      },
      "source": [
        "Nos quedamos con la parte relevante del conjunto de datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWQr6SeTgt33",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = df_train[[\"target\",\"text\"]]\n",
        "df_val = df_val[[\"target\",\"text\"]]\n",
        "df_test = df_test[[\"target\",\"text\"]]\n",
        "df_train.columns = [\"label\", \"sentence\"]\n",
        "df_train.index.name = \"idx\"\n",
        "df_train = df_train.reset_index()\n",
        "df_val.columns = [\"label\", \"sentence\"]\n",
        "df_val.index.name = \"idx\"\n",
        "df_val = df_val.reset_index()\n",
        "df_test.columns = [\"label\", \"sentence\"]\n",
        "df_test.index.name = \"idx\"\n",
        "df_test = df_test.reset_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6_QNHvagt37",
        "colab_type": "code",
        "outputId": "8527f584-2ec3-42ee-fda5-d30f72f43035",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "df_train.label.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    640000\n",
              "0    640000\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u03m0wC4gt39",
        "colab_type": "code",
        "outputId": "a8a28584-f074-483b-abd4-5c1510028e46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "df_val.label.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    80000\n",
              "0    80000\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-rF18M3gt3_",
        "colab_type": "text"
      },
      "source": [
        "## Algunas estadísticas una vez hemos preprocesado los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_TRf3aGgt3_",
        "colab_type": "text"
      },
      "source": [
        "Número medio de palabras por tweet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HB_PJ5t7gt3_",
        "colab_type": "code",
        "outputId": "93b2438f-9e4e-4799-d44e-adac2028a652",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.mean([len(sentence.split()) for sentence in df_train.sentence.values])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13.65478515625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcJ1LWl2gt4C",
        "colab_type": "text"
      },
      "source": [
        "Número de palabras distintas que aparecen en nuestro conjunto de entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTq-iFVTgt4C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_occurences_df = df_train.sentence.str.split(expand=True).stack().value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgy1SzuUgt4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_occurences_df = word_occurences_df.to_frame()\n",
        "word_occurences_df = word_occurences_df.reset_index()\n",
        "word_occurences_df.columns = [\"Word\", \"Occurences\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZ_SL-J-gt4H",
        "colab_type": "code",
        "outputId": "10395cfe-f360-4a6c-bbb4-0009aad392c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word_occurences_df.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "243871"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7uOoxLUgt4J",
        "colab_type": "text"
      },
      "source": [
        "Número de palabras que aparecen más de 2, 3, 4, 5 y 6 veces:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsTM0Etzgt4K",
        "colab_type": "code",
        "outputId": "c9355564-475b-43c5-d56c-f616ac38da53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word_occurences_df[word_occurences_df[\"Occurences\"] > 2].shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "68290"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yVwe8ougt4M",
        "colab_type": "code",
        "outputId": "fdec3a54-4bac-4fef-af7b-ed319630637a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word_occurences_df[word_occurences_df[\"Occurences\"] > 3].shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55151"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "pn1_gdy1gt4O",
        "colab_type": "code",
        "outputId": "fc4f2eef-c6ac-49a3-9248-667e2f09251f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word_occurences_df[word_occurences_df[\"Occurences\"] > 4].shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47193"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUNP2Epngt4Q",
        "colab_type": "code",
        "outputId": "6aca2f3b-af49-48bd-c6ac-71bb37d4d542",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word_occurences_df[word_occurences_df[\"Occurences\"] > 5].shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41715"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-F7OXvegt4S",
        "colab_type": "code",
        "outputId": "f979681d-20b5-4e3f-9e57-fede98d2078c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word_occurences_df[word_occurences_df[\"Occurences\"] > 6].shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37693"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgWm0-K1gt4U",
        "colab_type": "text"
      },
      "source": [
        "## Tokenización\n",
        "Finalmente traducimos el texto a índices del vocabulario. Para ello usaremos un tokenizador creado con Keras. Este tokenizador asignará a cada una de las ``max_features = 48000`` palabras que más ocurrencias tienen en el conjunto de entrenamiento un índice. El resto de palabras serán ignoradas. \n",
        "\n",
        "Es importante notar que hemos fijado ``max_features = 48000`` debido a que el número de palabras que aparecen más de 4 veces es de 47193 (lo acabamos de ver en la sección anterior). De esta forma ignoraremos las palabras que aparecen menos de 5 veces, de las cuales realmente no tenemos mucha información (por lo que será dificil que se aprenda algo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGcaf6INgt4V",
        "colab_type": "code",
        "outputId": "b4ebbc28-99c2-46e6-916a-cc9f1f8e65ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# NUEVO vocabulary_indices\n",
        "tokenizer = Tokenizer(num_words = max_features) #oov_token=None #Solo usaremos un vocabulario con max_features palabras\n",
        "tokenizer.fit_on_texts(list(df_train.sentence.values))\n",
        "#vocab_size = len(tokenizer.word_index) + 1\n",
        "#tokenizer.texts_to_sequences(...)\n",
        "#print(vocab_size)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 243871 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNoeEhAmgt4W",
        "colab_type": "text"
      },
      "source": [
        "Probamos a tokenizar algunas frases para hacernos una idea de lo que hace el tokenizador. La palabra 'himsik' no está en nuestro vocabulario (porque aparece menos de 5 veces en el conjunto de entrenamiento), luego el tokenizador la ignorará."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rupUG-VEgt4X",
        "colab_type": "code",
        "outputId": "6b9d1619-2a36-4015-e1be-013611657df3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer.texts_to_sequences([\"my father is so fat\", \"you are awesome himsik\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[6, 1185, 10, 19, 1116], [9, 40, 164]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aoq8Eb2fgt4Z",
        "colab_type": "text"
      },
      "source": [
        "Comprobamos como tras tokenizar, solo usaremos max_features palabras distintas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnITc6Uegt4Z",
        "colab_type": "code",
        "outputId": "e111125e-8fde-49e2-964e-6dd6b6dc0374",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_tweets_tokenized = tokenizer.texts_to_sequences(df_train.sentence)\n",
        "len(set([word_id for tweet in train_tweets_tokenized for word_id in tweet]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9hsf14-gt4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = sequence.pad_sequences(tokenizer.texts_to_sequences(df_train.sentence), maxlen=maxlen)\n",
        "y_train = df_train.label.values\n",
        "x_val = sequence.pad_sequences(tokenizer.texts_to_sequences(df_val.sentence), maxlen=maxlen)\n",
        "y_val = df_val.label.values\n",
        "x_test = sequence.pad_sequences(tokenizer.texts_to_sequences(df_test.sentence), maxlen=maxlen)\n",
        "y_test = df_test.label.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ot6xZaJgt4e",
        "colab_type": "text"
      },
      "source": [
        "## Creamos y entrenamos el modelo LSTM bidireccional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WatV9OOgt4e",
        "colab_type": "text"
      },
      "source": [
        "Preparamos la embedding matrix y creamos el la capa embedding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2_pj3CFgt4f",
        "colab_type": "code",
        "outputId": "06a1a649-4f28-43b8-f0d4-9f331003fce3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Preparing embedding matrix.')\n",
        "\n",
        "# prepare embedding matrix\n",
        "num_words = min(max_features, len(word_index) + 1)\n",
        "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "# load pre-trained word embeddings into an Embedding layer\n",
        "# note that we set trainable = False so as to keep the embeddings fixed\n",
        "embedding_layer = Embedding(num_words,\n",
        "                            embedding_dim,\n",
        "                            embeddings_initializer=Constant(embedding_matrix),\n",
        "                            input_length=maxlen,\n",
        "                            trainable=False) #Lo congelamos"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing embedding matrix.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgwfXUGFgt4h",
        "colab_type": "text"
      },
      "source": [
        "Construimos el modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlz0sryfgt4h",
        "colab_type": "code",
        "outputId": "0a3e66ca-aa75-4ec2-ee13-a9434448e76e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Build model...')\n",
        "model_LSTM_Bi = Sequential()\n",
        "#model_LSTM_Bi.add(Embedding(max_features, 128, input_length=maxlen))\n",
        "\n",
        "#sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "#embedded_sequences = embedding_layer(sequence_input)\n",
        "\n",
        "model_LSTM_Bi.add(embedding_layer)\n",
        "\n",
        "model_LSTM_Bi.add(Bidirectional(LSTM(64)))\n",
        "model_LSTM_Bi.add(Dropout(0.5))\n",
        "model_LSTM_Bi.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# try using different optimizers and different optimizer configs\n",
        "#De BERT\n",
        "#loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "#metric = tf.keras.metrics.SparseCategoricalAccuracy(\"accuracy\")\n",
        "#model.compile(optimizer=opt, loss=loss, metrics=[metric])\n",
        "\n",
        "#De BERT adaptado\n",
        "#loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "#metric = tf.keras.metrics.SparseCategoricalAccuracy(\"accuracy\")\n",
        "#model_LSTM_Bi.compile(optimizer = 'adam', loss=loss, metrics=[metric])\n",
        "\n",
        "#Original de esta LSTM\n",
        "model_LSTM_Bi.compile('adam', 'binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_Gh1RQXgt4j",
        "colab_type": "text"
      },
      "source": [
        "Definimos las callbacks y entrenamos el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2Oiyvsvgt4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_path = \"/content/drive/My Drive/\"\n",
        "#checkpoint_path = \"./\"\n",
        "\n",
        "class TimeHistory(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.times = []\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        self.epoch_time_start = time.time()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.times.append(time.time() - self.epoch_time_start)\n",
        "\n",
        "time_callback = TimeHistory()\n",
        "\n",
        "my_callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path + 'my_best_model_LSTM_Bi_WE.{epoch:02d}-{val_accuracy:.2f}.h5', \n",
        "    verbose=1, save_best_only=True, save_weights_only=False, monitor = 'val_accuracy', mode = 'max'), \n",
        "    time_callback\n",
        "  ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnrCWNNzgt4l",
        "colab_type": "code",
        "outputId": "19f11c6e-f7ca-4e0a-820d-1ceb647db04d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print('Train...')\n",
        "history = model_LSTM_Bi.fit(x_train, y_train,\n",
        "                            batch_size=batch_size,\n",
        "                            epochs=epochs,\n",
        "                            validation_data=(x_val, y_val),\n",
        "                            verbose = 1,\n",
        "                            callbacks=my_callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train...\n",
            "Epoch 1/20\n",
            "42665/42667 [============================>.] - ETA: 0s - loss: 0.4194 - accuracy: 0.8069\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.82350, saving model to /content/drive/My Drive/my_best_model_LSTM_Bi_WE.01-0.82.h5\n",
            "42667/42667 [==============================] - 372s 9ms/step - loss: 0.4194 - accuracy: 0.8069 - val_loss: 0.3908 - val_accuracy: 0.8235\n",
            "Epoch 2/20\n",
            "42666/42667 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8267\n",
            "Epoch 00002: val_accuracy improved from 0.82350 to 0.82936, saving model to /content/drive/My Drive/my_best_model_LSTM_Bi_WE.02-0.83.h5\n",
            "42667/42667 [==============================] - 373s 9ms/step - loss: 0.3845 - accuracy: 0.8267 - val_loss: 0.3787 - val_accuracy: 0.8294\n",
            "Epoch 3/20\n",
            "42663/42667 [============================>.] - ETA: 0s - loss: 0.3723 - accuracy: 0.8337\n",
            "Epoch 00003: val_accuracy improved from 0.82936 to 0.83202, saving model to /content/drive/My Drive/my_best_model_LSTM_Bi_WE.03-0.83.h5\n",
            "42667/42667 [==============================] - 373s 9ms/step - loss: 0.3723 - accuracy: 0.8337 - val_loss: 0.3753 - val_accuracy: 0.8320\n",
            "Epoch 4/20\n",
            "42664/42667 [============================>.] - ETA: 0s - loss: 0.3645 - accuracy: 0.8377\n",
            "Epoch 00004: val_accuracy did not improve from 0.83202\n",
            "42667/42667 [==============================] - 364s 9ms/step - loss: 0.3645 - accuracy: 0.8377 - val_loss: 0.3774 - val_accuracy: 0.8304\n",
            "Epoch 5/20\n",
            "42667/42667 [==============================] - ETA: 0s - loss: 0.3591 - accuracy: 0.8405\n",
            "Epoch 00005: val_accuracy improved from 0.83202 to 0.83205, saving model to /content/drive/My Drive/my_best_model_LSTM_Bi_WE.05-0.83.h5\n",
            "42667/42667 [==============================] - 371s 9ms/step - loss: 0.3591 - accuracy: 0.8405 - val_loss: 0.3753 - val_accuracy: 0.8321\n",
            "Epoch 6/20\n",
            "42662/42667 [============================>.] - ETA: 0s - loss: 0.3546 - accuracy: 0.8429\n",
            "Epoch 00006: val_accuracy improved from 0.83205 to 0.83297, saving model to /content/drive/My Drive/my_best_model_LSTM_Bi_WE.06-0.83.h5\n",
            "42667/42667 [==============================] - 370s 9ms/step - loss: 0.3546 - accuracy: 0.8429 - val_loss: 0.3735 - val_accuracy: 0.8330\n",
            "Epoch 7/20\n",
            "42666/42667 [============================>.] - ETA: 0s - loss: 0.3511 - accuracy: 0.8446\n",
            "Epoch 00007: val_accuracy did not improve from 0.83297\n",
            "42667/42667 [==============================] - 366s 9ms/step - loss: 0.3511 - accuracy: 0.8446 - val_loss: 0.3749 - val_accuracy: 0.8316\n",
            "Epoch 8/20\n",
            "42662/42667 [============================>.] - ETA: 0s - loss: 0.3482 - accuracy: 0.8463\n",
            "Epoch 00008: val_accuracy did not improve from 0.83297\n",
            "42667/42667 [==============================] - 367s 9ms/step - loss: 0.3482 - accuracy: 0.8463 - val_loss: 0.3752 - val_accuracy: 0.8315\n",
            "Epoch 9/20\n",
            "42666/42667 [============================>.] - ETA: 0s - loss: 0.3457 - accuracy: 0.8476\n",
            "Epoch 00009: val_accuracy improved from 0.83297 to 0.83357, saving model to /content/drive/My Drive/my_best_model_LSTM_Bi_WE.09-0.83.h5\n",
            "42667/42667 [==============================] - 371s 9ms/step - loss: 0.3457 - accuracy: 0.8476 - val_loss: 0.3742 - val_accuracy: 0.8336\n",
            "Epoch 10/20\n",
            "42663/42667 [============================>.] - ETA: 0s - loss: 0.3438 - accuracy: 0.8485\n",
            "Epoch 00010: val_accuracy did not improve from 0.83357\n",
            "42667/42667 [==============================] - 368s 9ms/step - loss: 0.3438 - accuracy: 0.8485 - val_loss: 0.3754 - val_accuracy: 0.8314\n",
            "Epoch 11/20\n",
            "42662/42667 [============================>.] - ETA: 0s - loss: 0.3420 - accuracy: 0.8494\n",
            "Epoch 00011: val_accuracy did not improve from 0.83357\n",
            "42667/42667 [==============================] - 366s 9ms/step - loss: 0.3420 - accuracy: 0.8494 - val_loss: 0.3762 - val_accuracy: 0.8325\n",
            "Epoch 12/20\n",
            "42663/42667 [============================>.] - ETA: 0s - loss: 0.3402 - accuracy: 0.8504\n",
            "Epoch 00012: val_accuracy did not improve from 0.83357\n",
            "42667/42667 [==============================] - 363s 9ms/step - loss: 0.3402 - accuracy: 0.8504 - val_loss: 0.3802 - val_accuracy: 0.8301\n",
            "Epoch 13/20\n",
            "42665/42667 [============================>.] - ETA: 0s - loss: 0.3390 - accuracy: 0.8508\n",
            "Epoch 00013: val_accuracy did not improve from 0.83357\n",
            "42667/42667 [==============================] - 360s 8ms/step - loss: 0.3390 - accuracy: 0.8508 - val_loss: 0.3781 - val_accuracy: 0.8320\n",
            "Epoch 14/20\n",
            "42663/42667 [============================>.] - ETA: 0s - loss: 0.3376 - accuracy: 0.8516\n",
            "Epoch 00014: val_accuracy did not improve from 0.83357\n",
            "42667/42667 [==============================] - 359s 8ms/step - loss: 0.3376 - accuracy: 0.8516 - val_loss: 0.3784 - val_accuracy: 0.8309\n",
            "Epoch 15/20\n",
            "42662/42667 [============================>.] - ETA: 0s - loss: 0.3368 - accuracy: 0.8520\n",
            "Epoch 00015: val_accuracy did not improve from 0.83357\n",
            "42667/42667 [==============================] - 359s 8ms/step - loss: 0.3368 - accuracy: 0.8520 - val_loss: 0.3799 - val_accuracy: 0.8315\n",
            "Epoch 16/20\n",
            "42663/42667 [============================>.] - ETA: 0s - loss: 0.3360 - accuracy: 0.8524\n",
            "Epoch 00016: val_accuracy did not improve from 0.83357\n",
            "42667/42667 [==============================] - 357s 8ms/step - loss: 0.3360 - accuracy: 0.8524 - val_loss: 0.3872 - val_accuracy: 0.8266\n",
            "Epoch 17/20\n",
            "42667/42667 [==============================] - ETA: 0s - loss: 0.3352 - accuracy: 0.8528\n",
            "Epoch 00017: val_accuracy did not improve from 0.83357\n",
            "42667/42667 [==============================] - 356s 8ms/step - loss: 0.3352 - accuracy: 0.8528 - val_loss: 0.3810 - val_accuracy: 0.8316\n",
            "Epoch 18/20\n",
            "42667/42667 [==============================] - ETA: 0s - loss: 0.3346 - accuracy: 0.8533\n",
            "Epoch 00018: val_accuracy did not improve from 0.83357\n",
            "42667/42667 [==============================] - 357s 8ms/step - loss: 0.3346 - accuracy: 0.8533 - val_loss: 0.3852 - val_accuracy: 0.8298\n",
            "Epoch 19/20\n",
            "42662/42667 [============================>.] - ETA: 0s - loss: 0.3344 - accuracy: 0.8534\n",
            "Epoch 00019: val_accuracy did not improve from 0.83357\n",
            "42667/42667 [==============================] - 363s 9ms/step - loss: 0.3344 - accuracy: 0.8533 - val_loss: 0.3846 - val_accuracy: 0.8298\n",
            "Epoch 20/20\n",
            "42662/42667 [============================>.] - ETA: 0s - loss: 0.3336 - accuracy: 0.8538\n",
            "Epoch 00020: val_accuracy did not improve from 0.83357\n",
            "42667/42667 [==============================] - 367s 9ms/step - loss: 0.3336 - accuracy: 0.8538 - val_loss: 0.3798 - val_accuracy: 0.8303\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcbyF5_rgt4o",
        "colab_type": "text"
      },
      "source": [
        "Lo evaluamos en el conjunto test:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0vwSco5gt4o",
        "colab_type": "code",
        "outputId": "369d3c80-4174-47f1-a624-acd39f4d9bb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "loss, acc = model_LSTM_Bi.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "print('Test loss:', loss)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5334/5334 [==============================] - 25s 5ms/step - loss: 0.3806 - accuracy: 0.8296\n",
            "Test loss: 0.3805888295173645\n",
            "Test accuracy: 0.8296375274658203\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24AmiuvLgt4q",
        "colab_type": "text"
      },
      "source": [
        "Guardamos el modelo y los datos que hemos ido recopilando durante el entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7B1YGD52gt4r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_LSTM_Bi.save(checkpoint_path + 'final_model_LSTM_Bi_WE.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L218o3-Qgt4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert the history.history dict to a pandas DataFrame:     \n",
        "hist_df = pd.DataFrame(history.history) \n",
        "\n",
        "\n",
        "# save to csv: \n",
        "hist_csv_file = checkpoint_path + 'history_LSTM_Bi_WE.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZPXaxCZgt4y",
        "colab_type": "code",
        "outputId": "013bda98-8925-49f1-c34d-b9a81489c5b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "time_callback.times"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[381.38500022888184,\n",
              " 373.1717915534973,\n",
              " 373.3835184574127,\n",
              " 364.3669447898865,\n",
              " 370.7132284641266,\n",
              " 369.80929255485535,\n",
              " 366.3093695640564,\n",
              " 366.94583201408386,\n",
              " 371.34428429603577,\n",
              " 368.5071392059326,\n",
              " 365.5348379611969,\n",
              " 363.39785146713257,\n",
              " 360.41564297676086,\n",
              " 359.44333004951477,\n",
              " 359.2808494567871,\n",
              " 356.675998210907,\n",
              " 356.39134097099304,\n",
              " 357.43105125427246,\n",
              " 363.16758966445923,\n",
              " 366.8707072734833]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXe1xdk2gt40",
        "colab_type": "code",
        "outputId": "3e62e707-6907-4259-89b1-7d23f323270a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "hist_df[\"times\"] = time_callback.times\n",
        "hist_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>times</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.419442</td>\n",
              "      <td>0.806927</td>\n",
              "      <td>0.390838</td>\n",
              "      <td>0.823500</td>\n",
              "      <td>381.385000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.384470</td>\n",
              "      <td>0.826697</td>\n",
              "      <td>0.378699</td>\n",
              "      <td>0.829356</td>\n",
              "      <td>373.171792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.372340</td>\n",
              "      <td>0.833673</td>\n",
              "      <td>0.375309</td>\n",
              "      <td>0.832025</td>\n",
              "      <td>373.383518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.364484</td>\n",
              "      <td>0.837668</td>\n",
              "      <td>0.377391</td>\n",
              "      <td>0.830387</td>\n",
              "      <td>364.366945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.359072</td>\n",
              "      <td>0.840523</td>\n",
              "      <td>0.375273</td>\n",
              "      <td>0.832050</td>\n",
              "      <td>370.713228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.354643</td>\n",
              "      <td>0.842912</td>\n",
              "      <td>0.373484</td>\n",
              "      <td>0.832969</td>\n",
              "      <td>369.809293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.351082</td>\n",
              "      <td>0.844605</td>\n",
              "      <td>0.374886</td>\n",
              "      <td>0.831569</td>\n",
              "      <td>366.309370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.348174</td>\n",
              "      <td>0.846277</td>\n",
              "      <td>0.375204</td>\n",
              "      <td>0.831519</td>\n",
              "      <td>366.945832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.345734</td>\n",
              "      <td>0.847591</td>\n",
              "      <td>0.374238</td>\n",
              "      <td>0.833569</td>\n",
              "      <td>371.344284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.343779</td>\n",
              "      <td>0.848465</td>\n",
              "      <td>0.375380</td>\n",
              "      <td>0.831438</td>\n",
              "      <td>368.507139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.341985</td>\n",
              "      <td>0.849409</td>\n",
              "      <td>0.376178</td>\n",
              "      <td>0.832469</td>\n",
              "      <td>365.534838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.340214</td>\n",
              "      <td>0.850366</td>\n",
              "      <td>0.380158</td>\n",
              "      <td>0.830125</td>\n",
              "      <td>363.397851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.339023</td>\n",
              "      <td>0.850794</td>\n",
              "      <td>0.378117</td>\n",
              "      <td>0.832044</td>\n",
              "      <td>360.415643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.337572</td>\n",
              "      <td>0.851567</td>\n",
              "      <td>0.378420</td>\n",
              "      <td>0.830850</td>\n",
              "      <td>359.443330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.336794</td>\n",
              "      <td>0.852010</td>\n",
              "      <td>0.379940</td>\n",
              "      <td>0.831513</td>\n",
              "      <td>359.280849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.336006</td>\n",
              "      <td>0.852387</td>\n",
              "      <td>0.387219</td>\n",
              "      <td>0.826600</td>\n",
              "      <td>356.675998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.335194</td>\n",
              "      <td>0.852750</td>\n",
              "      <td>0.380994</td>\n",
              "      <td>0.831600</td>\n",
              "      <td>356.391341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.334568</td>\n",
              "      <td>0.853302</td>\n",
              "      <td>0.385223</td>\n",
              "      <td>0.829775</td>\n",
              "      <td>357.431051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.334403</td>\n",
              "      <td>0.853348</td>\n",
              "      <td>0.384575</td>\n",
              "      <td>0.829794</td>\n",
              "      <td>363.167590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.333578</td>\n",
              "      <td>0.853788</td>\n",
              "      <td>0.379793</td>\n",
              "      <td>0.830262</td>\n",
              "      <td>366.870707</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        loss  accuracy  val_loss  val_accuracy       times\n",
              "0   0.419442  0.806927  0.390838      0.823500  381.385000\n",
              "1   0.384470  0.826697  0.378699      0.829356  373.171792\n",
              "2   0.372340  0.833673  0.375309      0.832025  373.383518\n",
              "3   0.364484  0.837668  0.377391      0.830387  364.366945\n",
              "4   0.359072  0.840523  0.375273      0.832050  370.713228\n",
              "5   0.354643  0.842912  0.373484      0.832969  369.809293\n",
              "6   0.351082  0.844605  0.374886      0.831569  366.309370\n",
              "7   0.348174  0.846277  0.375204      0.831519  366.945832\n",
              "8   0.345734  0.847591  0.374238      0.833569  371.344284\n",
              "9   0.343779  0.848465  0.375380      0.831438  368.507139\n",
              "10  0.341985  0.849409  0.376178      0.832469  365.534838\n",
              "11  0.340214  0.850366  0.380158      0.830125  363.397851\n",
              "12  0.339023  0.850794  0.378117      0.832044  360.415643\n",
              "13  0.337572  0.851567  0.378420      0.830850  359.443330\n",
              "14  0.336794  0.852010  0.379940      0.831513  359.280849\n",
              "15  0.336006  0.852387  0.387219      0.826600  356.675998\n",
              "16  0.335194  0.852750  0.380994      0.831600  356.391341\n",
              "17  0.334568  0.853302  0.385223      0.829775  357.431051\n",
              "18  0.334403  0.853348  0.384575      0.829794  363.167590\n",
              "19  0.333578  0.853788  0.379793      0.830262  366.870707"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLmzIwbBgt42",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save to csv: \n",
        "hist_csv_file = checkpoint_path + 'history_LSTM_Bi_WE_with_times.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qID6-c_ugt49",
        "colab_type": "text"
      },
      "source": [
        "## Creamos y entrenamos el modelo LSTM-CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QE8UXcvgt49",
        "colab_type": "text"
      },
      "source": [
        "Construimos el modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4QYDs6Qgt4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path + 'my_best_model_LSTM-CNN_WE.{epoch:02d}-{val_accuracy:.2f}.h5', \n",
        "    verbose=1, save_best_only=True, save_weights_only=False, monitor = 'val_accuracy', mode = 'max'), \n",
        "    time_callback\n",
        "  ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkw5nISggt5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load pre-trained word embeddings into an Embedding layer\n",
        "# note that we set trainable = False so as to keep the embeddings fixed\n",
        "embedding_layer = Embedding(num_words,\n",
        "                            embedding_dim,\n",
        "                            embeddings_initializer=Constant(embedding_matrix),\n",
        "                            input_length=maxlen,\n",
        "                            trainable=False) #Lo congelamos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DYmZi0Cgt5D",
        "colab_type": "code",
        "outputId": "741c5a9a-4300-4bc9-a2ba-d4af71073961",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Build model...')\n",
        "\n",
        "model = Sequential()\n",
        "model.add(embedding_layer) \n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv1D(filters,\n",
        "                 kernel_size,\n",
        "                 padding='valid',\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "model.add(MaxPooling1D(pool_size=pool_size))\n",
        "model.add(LSTM(lstm_output_size))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56uJHLfkgt5H",
        "colab_type": "text"
      },
      "source": [
        "Entrenamos el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdI4y1Jqgt5H",
        "colab_type": "code",
        "outputId": "7d998736-793e-4f5b-d6e6-4db6c5ceb52d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print('Train...')\n",
        "history = model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_val, y_val),\n",
        "              verbose = 1,\n",
        "              callbacks=my_callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train...\n",
            "Epoch 1/20\n",
            "42667/42667 [==============================] - ETA: 0s - loss: 0.4548 - accuracy: 0.7831\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.80712, saving model to /content/drive/My Drive/my_best_model_LSTM-CNN_WE.01-0.81.h5\n",
            "42667/42667 [==============================] - 247s 6ms/step - loss: 0.4548 - accuracy: 0.7831 - val_loss: 0.4168 - val_accuracy: 0.8071\n",
            "Epoch 2/20\n",
            "42660/42667 [============================>.] - ETA: 0s - loss: 0.4318 - accuracy: 0.7978\n",
            "Epoch 00002: val_accuracy improved from 0.80712 to 0.81144, saving model to /content/drive/My Drive/my_best_model_LSTM-CNN_WE.02-0.81.h5\n",
            "42667/42667 [==============================] - 246s 6ms/step - loss: 0.4318 - accuracy: 0.7978 - val_loss: 0.4110 - val_accuracy: 0.8114\n",
            "Epoch 3/20\n",
            "42664/42667 [============================>.] - ETA: 0s - loss: 0.4254 - accuracy: 0.8017\n",
            "Epoch 00003: val_accuracy improved from 0.81144 to 0.81275, saving model to /content/drive/My Drive/my_best_model_LSTM-CNN_WE.03-0.81.h5\n",
            "42667/42667 [==============================] - 246s 6ms/step - loss: 0.4254 - accuracy: 0.8017 - val_loss: 0.4083 - val_accuracy: 0.8127\n",
            "Epoch 4/20\n",
            "42663/42667 [============================>.] - ETA: 0s - loss: 0.4223 - accuracy: 0.8036\n",
            "Epoch 00004: val_accuracy improved from 0.81275 to 0.81556, saving model to /content/drive/My Drive/my_best_model_LSTM-CNN_WE.04-0.82.h5\n",
            "42667/42667 [==============================] - 245s 6ms/step - loss: 0.4223 - accuracy: 0.8036 - val_loss: 0.4036 - val_accuracy: 0.8156\n",
            "Epoch 5/20\n",
            "42664/42667 [============================>.] - ETA: 0s - loss: 0.4207 - accuracy: 0.8045\n",
            "Epoch 00005: val_accuracy improved from 0.81556 to 0.81606, saving model to /content/drive/My Drive/my_best_model_LSTM-CNN_WE.05-0.82.h5\n",
            "42667/42667 [==============================] - 246s 6ms/step - loss: 0.4207 - accuracy: 0.8045 - val_loss: 0.4037 - val_accuracy: 0.8161\n",
            "Epoch 6/20\n",
            "42661/42667 [============================>.] - ETA: 0s - loss: 0.4186 - accuracy: 0.8061\n",
            "Epoch 00006: val_accuracy improved from 0.81606 to 0.81679, saving model to /content/drive/My Drive/my_best_model_LSTM-CNN_WE.06-0.82.h5\n",
            "42667/42667 [==============================] - 244s 6ms/step - loss: 0.4187 - accuracy: 0.8060 - val_loss: 0.4015 - val_accuracy: 0.8168\n",
            "Epoch 7/20\n",
            "42662/42667 [============================>.] - ETA: 0s - loss: 0.4176 - accuracy: 0.8067\n",
            "Epoch 00007: val_accuracy improved from 0.81679 to 0.81729, saving model to /content/drive/My Drive/my_best_model_LSTM-CNN_WE.07-0.82.h5\n",
            "42667/42667 [==============================] - 244s 6ms/step - loss: 0.4176 - accuracy: 0.8066 - val_loss: 0.4011 - val_accuracy: 0.8173\n",
            "Epoch 8/20\n",
            "42665/42667 [============================>.] - ETA: 0s - loss: 0.4168 - accuracy: 0.8071\n",
            "Epoch 00008: val_accuracy did not improve from 0.81729\n",
            "42667/42667 [==============================] - 239s 6ms/step - loss: 0.4168 - accuracy: 0.8071 - val_loss: 0.4009 - val_accuracy: 0.8167\n",
            "Epoch 9/20\n",
            "42660/42667 [============================>.] - ETA: 0s - loss: 0.4161 - accuracy: 0.8077\n",
            "Epoch 00009: val_accuracy improved from 0.81729 to 0.81746, saving model to /content/drive/My Drive/my_best_model_LSTM-CNN_WE.09-0.82.h5\n",
            "42667/42667 [==============================] - 242s 6ms/step - loss: 0.4161 - accuracy: 0.8077 - val_loss: 0.4010 - val_accuracy: 0.8175\n",
            "Epoch 10/20\n",
            "42664/42667 [============================>.] - ETA: 0s - loss: 0.4160 - accuracy: 0.8076\n",
            "Epoch 00010: val_accuracy did not improve from 0.81746\n",
            "42667/42667 [==============================] - 239s 6ms/step - loss: 0.4160 - accuracy: 0.8076 - val_loss: 0.4010 - val_accuracy: 0.8173\n",
            "Epoch 11/20\n",
            "42662/42667 [============================>.] - ETA: 0s - loss: 0.4152 - accuracy: 0.8082\n",
            "Epoch 00011: val_accuracy did not improve from 0.81746\n",
            "42667/42667 [==============================] - 240s 6ms/step - loss: 0.4152 - accuracy: 0.8082 - val_loss: 0.4030 - val_accuracy: 0.8160\n",
            "Epoch 12/20\n",
            "42665/42667 [============================>.] - ETA: 0s - loss: 0.4147 - accuracy: 0.8086\n",
            "Epoch 00012: val_accuracy did not improve from 0.81746\n",
            "42667/42667 [==============================] - 242s 6ms/step - loss: 0.4147 - accuracy: 0.8086 - val_loss: 0.4023 - val_accuracy: 0.8162\n",
            "Epoch 13/20\n",
            "42661/42667 [============================>.] - ETA: 0s - loss: 0.4147 - accuracy: 0.8085\n",
            "Epoch 00013: val_accuracy improved from 0.81746 to 0.81847, saving model to /content/drive/My Drive/my_best_model_LSTM-CNN_WE.13-0.82.h5\n",
            "42667/42667 [==============================] - 245s 6ms/step - loss: 0.4147 - accuracy: 0.8086 - val_loss: 0.4003 - val_accuracy: 0.8185\n",
            "Epoch 14/20\n",
            "42665/42667 [============================>.] - ETA: 0s - loss: 0.4145 - accuracy: 0.8086\n",
            "Epoch 00014: val_accuracy did not improve from 0.81847\n",
            "42667/42667 [==============================] - 239s 6ms/step - loss: 0.4145 - accuracy: 0.8086 - val_loss: 0.3993 - val_accuracy: 0.8183\n",
            "Epoch 15/20\n",
            "42667/42667 [==============================] - ETA: 0s - loss: 0.4142 - accuracy: 0.8088\n",
            "Epoch 00015: val_accuracy did not improve from 0.81847\n",
            "42667/42667 [==============================] - 238s 6ms/step - loss: 0.4142 - accuracy: 0.8088 - val_loss: 0.3999 - val_accuracy: 0.8181\n",
            "Epoch 16/20\n",
            "42667/42667 [==============================] - ETA: 0s - loss: 0.4137 - accuracy: 0.8091\n",
            "Epoch 00016: val_accuracy improved from 0.81847 to 0.81896, saving model to /content/drive/My Drive/my_best_model_LSTM-CNN_WE.16-0.82.h5\n",
            "42667/42667 [==============================] - 241s 6ms/step - loss: 0.4137 - accuracy: 0.8091 - val_loss: 0.3992 - val_accuracy: 0.8190\n",
            "Epoch 17/20\n",
            "42659/42667 [============================>.] - ETA: 0s - loss: 0.4137 - accuracy: 0.8092\n",
            "Epoch 00017: val_accuracy did not improve from 0.81896\n",
            "42667/42667 [==============================] - 238s 6ms/step - loss: 0.4137 - accuracy: 0.8092 - val_loss: 0.4017 - val_accuracy: 0.8180\n",
            "Epoch 18/20\n",
            "42665/42667 [============================>.] - ETA: 0s - loss: 0.4135 - accuracy: 0.8093\n",
            "Epoch 00018: val_accuracy did not improve from 0.81896\n",
            "42667/42667 [==============================] - 237s 6ms/step - loss: 0.4135 - accuracy: 0.8093 - val_loss: 0.3990 - val_accuracy: 0.8189\n",
            "Epoch 19/20\n",
            "42660/42667 [============================>.] - ETA: 0s - loss: 0.4133 - accuracy: 0.8095\n",
            "Epoch 00019: val_accuracy did not improve from 0.81896\n",
            "42667/42667 [==============================] - 239s 6ms/step - loss: 0.4133 - accuracy: 0.8095 - val_loss: 0.4006 - val_accuracy: 0.8177\n",
            "Epoch 20/20\n",
            "42666/42667 [============================>.] - ETA: 0s - loss: 0.4134 - accuracy: 0.8091\n",
            "Epoch 00020: val_accuracy did not improve from 0.81896\n",
            "42667/42667 [==============================] - 236s 6ms/step - loss: 0.4134 - accuracy: 0.8091 - val_loss: 0.4010 - val_accuracy: 0.8171\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QoaZmHjgt5K",
        "colab_type": "text"
      },
      "source": [
        "Lo evaluamos en el conjunto test:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FSMG2WUgt5K",
        "colab_type": "code",
        "outputId": "040b781f-7f5a-4f9e-9318-2f2b1bbf0cef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "loss, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "print('Test loss:', loss)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5334/5334 [==============================] - 17s 3ms/step - loss: 0.4011 - accuracy: 0.8175\n",
            "Test loss: 0.40108928084373474\n",
            "Test accuracy: 0.8174750208854675\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5h1gPuegt5O",
        "colab_type": "text"
      },
      "source": [
        "Guardamos el modelo y los datos que hemos ido recopilando durante el entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GhT63_pgt5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(checkpoint_path + './final_model_LSTM-CNN_WE.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVszoqGTgt5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert the history.history dict to a pandas DataFrame:     \n",
        "hist_df = pd.DataFrame(history.history) \n",
        "\n",
        "\n",
        "# or save to csv: \n",
        "hist_csv_file = checkpoint_path + 'history_LSTM-CNN_WE.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAWhjKlpgt5S",
        "colab_type": "code",
        "outputId": "a1946e62-6fbf-4317-8bcb-bacc2ff53517",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "time_callback.times"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[249.00644278526306,\n",
              " 246.42788124084473,\n",
              " 245.67459964752197,\n",
              " 245.157888174057,\n",
              " 245.5422441959381,\n",
              " 243.9165802001953,\n",
              " 243.54245257377625,\n",
              " 238.52641987800598,\n",
              " 242.12065958976746,\n",
              " 238.6482434272766,\n",
              " 239.6029350757599,\n",
              " 241.6167447566986,\n",
              " 244.5101420879364,\n",
              " 238.62593126296997,\n",
              " 238.50634360313416,\n",
              " 241.39828538894653,\n",
              " 238.1961395740509,\n",
              " 237.45863366127014,\n",
              " 238.69373393058777,\n",
              " 236.3691189289093]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVNh0gAGgt5U",
        "colab_type": "code",
        "outputId": "6c090b49-8fb2-4511-d685-f8ffbf726a29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "hist_df[\"times\"] = time_callback.times\n",
        "hist_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>times</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.454774</td>\n",
              "      <td>0.783092</td>\n",
              "      <td>0.416801</td>\n",
              "      <td>0.807125</td>\n",
              "      <td>249.006443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.431754</td>\n",
              "      <td>0.797836</td>\n",
              "      <td>0.410984</td>\n",
              "      <td>0.811437</td>\n",
              "      <td>246.427881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.425398</td>\n",
              "      <td>0.801681</td>\n",
              "      <td>0.408278</td>\n",
              "      <td>0.812750</td>\n",
              "      <td>245.674600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.422348</td>\n",
              "      <td>0.803635</td>\n",
              "      <td>0.403609</td>\n",
              "      <td>0.815562</td>\n",
              "      <td>245.157888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.420724</td>\n",
              "      <td>0.804530</td>\n",
              "      <td>0.403732</td>\n",
              "      <td>0.816063</td>\n",
              "      <td>245.542244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.418654</td>\n",
              "      <td>0.806048</td>\n",
              "      <td>0.401459</td>\n",
              "      <td>0.816794</td>\n",
              "      <td>243.916580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.417566</td>\n",
              "      <td>0.806650</td>\n",
              "      <td>0.401121</td>\n",
              "      <td>0.817288</td>\n",
              "      <td>243.542453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.416775</td>\n",
              "      <td>0.807144</td>\n",
              "      <td>0.400908</td>\n",
              "      <td>0.816744</td>\n",
              "      <td>238.526420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.416085</td>\n",
              "      <td>0.807677</td>\n",
              "      <td>0.400974</td>\n",
              "      <td>0.817463</td>\n",
              "      <td>242.120660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.416013</td>\n",
              "      <td>0.807557</td>\n",
              "      <td>0.401044</td>\n",
              "      <td>0.817256</td>\n",
              "      <td>238.648243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.415213</td>\n",
              "      <td>0.808218</td>\n",
              "      <td>0.402964</td>\n",
              "      <td>0.816050</td>\n",
              "      <td>239.602935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.414674</td>\n",
              "      <td>0.808634</td>\n",
              "      <td>0.402316</td>\n",
              "      <td>0.816188</td>\n",
              "      <td>241.616745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.414733</td>\n",
              "      <td>0.808550</td>\n",
              "      <td>0.400325</td>\n",
              "      <td>0.818469</td>\n",
              "      <td>244.510142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.414514</td>\n",
              "      <td>0.808552</td>\n",
              "      <td>0.399327</td>\n",
              "      <td>0.818319</td>\n",
              "      <td>238.625931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.414159</td>\n",
              "      <td>0.808845</td>\n",
              "      <td>0.399882</td>\n",
              "      <td>0.818119</td>\n",
              "      <td>238.506344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.413729</td>\n",
              "      <td>0.809100</td>\n",
              "      <td>0.399165</td>\n",
              "      <td>0.818963</td>\n",
              "      <td>241.398285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.413698</td>\n",
              "      <td>0.809220</td>\n",
              "      <td>0.401721</td>\n",
              "      <td>0.817981</td>\n",
              "      <td>238.196140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.413486</td>\n",
              "      <td>0.809277</td>\n",
              "      <td>0.398972</td>\n",
              "      <td>0.818862</td>\n",
              "      <td>237.458634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.413301</td>\n",
              "      <td>0.809518</td>\n",
              "      <td>0.400628</td>\n",
              "      <td>0.817688</td>\n",
              "      <td>238.693734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.413379</td>\n",
              "      <td>0.809124</td>\n",
              "      <td>0.401036</td>\n",
              "      <td>0.817100</td>\n",
              "      <td>236.369119</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        loss  accuracy  val_loss  val_accuracy       times\n",
              "0   0.454774  0.783092  0.416801      0.807125  249.006443\n",
              "1   0.431754  0.797836  0.410984      0.811437  246.427881\n",
              "2   0.425398  0.801681  0.408278      0.812750  245.674600\n",
              "3   0.422348  0.803635  0.403609      0.815562  245.157888\n",
              "4   0.420724  0.804530  0.403732      0.816063  245.542244\n",
              "5   0.418654  0.806048  0.401459      0.816794  243.916580\n",
              "6   0.417566  0.806650  0.401121      0.817288  243.542453\n",
              "7   0.416775  0.807144  0.400908      0.816744  238.526420\n",
              "8   0.416085  0.807677  0.400974      0.817463  242.120660\n",
              "9   0.416013  0.807557  0.401044      0.817256  238.648243\n",
              "10  0.415213  0.808218  0.402964      0.816050  239.602935\n",
              "11  0.414674  0.808634  0.402316      0.816188  241.616745\n",
              "12  0.414733  0.808550  0.400325      0.818469  244.510142\n",
              "13  0.414514  0.808552  0.399327      0.818319  238.625931\n",
              "14  0.414159  0.808845  0.399882      0.818119  238.506344\n",
              "15  0.413729  0.809100  0.399165      0.818963  241.398285\n",
              "16  0.413698  0.809220  0.401721      0.817981  238.196140\n",
              "17  0.413486  0.809277  0.398972      0.818862  237.458634\n",
              "18  0.413301  0.809518  0.400628      0.817688  238.693734\n",
              "19  0.413379  0.809124  0.401036      0.817100  236.369119"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WZxjGvYgt5V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save to csv: \n",
        "hist_csv_file = checkpoint_path + 'history_LSTM-CNN_WE_with_times.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}