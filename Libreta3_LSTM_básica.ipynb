{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Libreta3 - LSTM básica.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joSanchez28/BERT_on_tweets/blob/master/Libreta3_LSTM_b%C3%A1sica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mps5KubM38HE",
        "colab_type": "text"
      },
      "source": [
        "# LSTMs para clasificación de sentimientos\n",
        "\n",
        "En esta libreta creamos un modelo de forma sencilla con Keras usando unidades recurrentes LSTM de tipo bidireccional y lo entrenamos con nuestro conjunto de tweets.\n",
        "\n",
        "En primer lugar importamos los paquetes necesarios."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyAsTZcD38HF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
        "#Para la LSTM-CNN\n",
        "from tensorflow.keras.layers import Activation \n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
        "##\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5japeD538HK",
        "colab_type": "text"
      },
      "source": [
        "Parámetros para el modelo y el entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMf5YeTL38HL",
        "colab_type": "code",
        "outputId": "97d1a5b2-3e59-42d6-ba8f-0ad048b3842c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Embedding\n",
        "#max_features = 20000 #Original\n",
        "max_features = 48000 #Fijado viendo que el nº de palabras que aparece al menos 5 veces en el conjunto de entrenamiento es 47193\n",
        "#maxlen = 100 #Original\n",
        "#maxlen = 150 #La que usé\n",
        "maxlen = 40\n",
        "embedding_size = 128\n",
        "\n",
        "# Convolution\n",
        "kernel_size = 5\n",
        "filters = 64\n",
        "pool_size = 4\n",
        "\n",
        "# LSTM\n",
        "lstm_output_size = 70\n",
        "\n",
        "# Training\n",
        "batch_size = 30\n",
        "epochs = 8\n",
        "\n",
        "'''\n",
        "Note:\n",
        "batch_size is highly sensitive.\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nNote:\\nbatch_size is highly sensitive.\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sh0wFd_B38HN",
        "colab_type": "text"
      },
      "source": [
        "## Carga de los conjuntos de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6v5WTep38HO",
        "colab_type": "code",
        "outputId": "dbc810ee-6a82-4bc7-cc79-22c9d3a6aaa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GY08-dyM38HQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cargamos los tres conjuntos de datos\n",
        "data_path = \"/content/drive/My Drive/Datos/\"\n",
        "#data_path = \"../Datos/\"\n",
        "df_train = pd.read_csv(data_path + \"train_set.csv\")\n",
        "df_val = pd.read_csv(data_path + \"val_set.csv\")\n",
        "df_test = pd.read_csv(data_path + \"test_set.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkTkJVDS38HT",
        "colab_type": "text"
      },
      "source": [
        "## Preprocesado del conjunto de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8S3ENJt138HT",
        "colab_type": "text"
      },
      "source": [
        "Al igual que hicimos en la libreta 2 con el modelo BERT, sustituimos las URLs por la palabra URL y los nombres de usuario por la palabra USER. Además, esta vez quitamos todos los signos de puntuación y ponemos todo el texto en minúscula."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eDJYURP38HU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Para detectar urls y sustituirlas por URL\n",
        "TEXT_URL = \"https?:\\S+|http?:\\S|www\\.\\S+|\\S+\\.(com|org|co|us|uk|net|gov|edu)\"\n",
        "# Para detectar nombres de usuario y sustituirlos por USER\n",
        "TEXT_USER = \"@\\S+\"\n",
        "# Para quitar signos de puntuación o caracteres extraños\n",
        "TEXT_CLEANING = \"[^A-Za-z0-9]+\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2Ie5NWt38HW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(text, stem=False):\n",
        "    text = re.sub(TEXT_URL,  'URL',    text)           # Cambiamos las URLs por la palabra 'URL'\n",
        "    text = re.sub(TEXT_USER,  'USER', text)           # Cambiamos los nombres de usuario por la palabra 'USER'\n",
        "    text = re.sub(r'\\s+', ' ',   text).strip()        # Eliminamos dobles espacios en blanco y los espacios en blanco al principio o al final\n",
        "    text = re.sub(TEXT_CLEANING, ' ', str(text).lower()) # Eliminamos signos de puntuación y caracteres no alfanuméricos y lo ponemos en minuscula\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WP3MR-S38HZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.text = df_train.text.apply(lambda x: preprocess(x))\n",
        "df_val.text = df_val.text.apply(lambda x: preprocess(x))\n",
        "df_test.text = df_test.text.apply(lambda x: preprocess(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCyJrPMr38Hb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decode_map = {0: 0, 4: 1}\n",
        "def decode_sentiment(label):\n",
        "    return decode_map[int(label)]\n",
        "\n",
        "df_train.target = df_train.target.apply(lambda x: decode_sentiment(x))\n",
        "df_val.target = df_val.target.apply(lambda x: decode_sentiment(x))\n",
        "df_test.target = df_test.target.apply(lambda x: decode_sentiment(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43Qbz4IL38Hf",
        "colab_type": "text"
      },
      "source": [
        "Nos quedamos con la parte relevante del conjunto de datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jB1CpJi38Hg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = df_train[[\"target\",\"text\"]]\n",
        "df_val = df_val[[\"target\",\"text\"]]\n",
        "df_test = df_test[[\"target\",\"text\"]]\n",
        "df_train.columns = [\"label\", \"sentence\"]\n",
        "df_train.index.name = \"idx\"\n",
        "df_train = df_train.reset_index()\n",
        "df_val.columns = [\"label\", \"sentence\"]\n",
        "df_val.index.name = \"idx\"\n",
        "df_val = df_val.reset_index()\n",
        "df_test.columns = [\"label\", \"sentence\"]\n",
        "df_test.index.name = \"idx\"\n",
        "df_test = df_test.reset_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63R8E6tk38Hi",
        "colab_type": "code",
        "outputId": "c58830b4-f122-4d92-beb1-69a0b1bc08d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "df_train.label.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    640000\n",
              "0    640000\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1ra83Od38Hl",
        "colab_type": "code",
        "outputId": "b8f75a14-7e8b-4747-9f5c-2b386ae7b5f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "df_val.label.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    80000\n",
              "0    80000\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x8rC9HT38Ho",
        "colab_type": "text"
      },
      "source": [
        "## Algunas estadísticas una vez hemos preprocesado los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su-a0NA138Ho",
        "colab_type": "text"
      },
      "source": [
        "Número medio de palabras por tweet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlvGCC9A38Ho",
        "colab_type": "code",
        "outputId": "c62b84b9-d878-49ba-952f-60da0b9055d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.mean([len(sentence.split()) for sentence in df_train.sentence.values])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13.65478515625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOJyO6VG38Hq",
        "colab_type": "text"
      },
      "source": [
        "Número de palabras distintas que aparecen en nuestro conjunto de entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl3peke738Hr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_occurences_df = df_train.sentence.str.split(expand=True).stack().value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahY0gH0r38Ht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_occurences_df = word_occurences_df.to_frame()\n",
        "word_occurences_df = word_occurences_df.reset_index()\n",
        "word_occurences_df.columns = [\"Word\", \"Occurences\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICc-th9h38Hv",
        "colab_type": "code",
        "outputId": "32b68d29-abfd-4606-e131-6809039ca180",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word_occurences_df.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "243871"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNvq3jA638Hx",
        "colab_type": "text"
      },
      "source": [
        "Número de palabras que aparecen más de 2, 3, 4, 5 y 6 veces:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lgqbx3jj38Hx",
        "colab_type": "code",
        "outputId": "5b83ebbd-4a1c-4fff-f0ec-6a024cd5177c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word_occurences_df[word_occurences_df[\"Occurences\"] > 2].shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "68290"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "panR3F6e38H0",
        "colab_type": "code",
        "outputId": "861967d7-2686-4f4b-b12f-36d5f6dadea8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word_occurences_df[word_occurences_df[\"Occurences\"] > 3].shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55151"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "AKWbtYVt38H2",
        "colab_type": "code",
        "outputId": "47833d8d-8f7b-41d8-9a4e-acb3c95909a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word_occurences_df[word_occurences_df[\"Occurences\"] > 4].shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47193"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeRkqYw-38H4",
        "colab_type": "code",
        "outputId": "74f37638-c02d-4358-8d99-5f69658d9bf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word_occurences_df[word_occurences_df[\"Occurences\"] > 5].shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41715"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2oIlpWk38H6",
        "colab_type": "code",
        "outputId": "d72d1ba7-39fb-4b12-8e13-8d8323604ddc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word_occurences_df[word_occurences_df[\"Occurences\"] > 6].shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37693"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4DY-8cs38H8",
        "colab_type": "text"
      },
      "source": [
        "## Tokenización\n",
        "Finalmente traducimos el texto a índices del vocabulario. Para ello usaremos un tokenizador creado con Keras. Este tokenizador asignará a cada una de las ``max_features = 48000`` palabras que más ocurrencias tienen en el conjunto de entrenamiento un índice. El resto de palabras serán ignoradas. \n",
        "\n",
        "Es importante notar que hemos fijado ``max_features = 48000`` debido a que el número de palabras que aparecen más de 4 veces es de 47193 (lo acabamos de ver en la sección anterior). De esta forma ignoraremos las palabras que aparecen menos de 5 veces, de las cuales realmente no tenemos mucha información (por lo que será dificil que se aprenda algo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYMgOfWO38H9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NUEVO vocabulary_indices\n",
        "tokenizer = Tokenizer(num_words = max_features) #oov_token=None #Solo usaremos un vocabulario con max_features palabras\n",
        "tokenizer.fit_on_texts(list(df_train.sentence.values))\n",
        "#vocab_size = len(tokenizer.word_index) + 1\n",
        "#tokenizer.texts_to_sequences(...)\n",
        "#print(vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkGhGfJX38H_",
        "colab_type": "text"
      },
      "source": [
        "Probamos a tokenizar algunas frases para hacernos una idea de lo que hace el tokenizador. La palabra 'himsik' no está en nuestro vocabulario (porque aparece menos de 5 veces en el conjunto de entrenamiento), luego el tokenizador la ignorará."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yoo-z5Mi38H_",
        "colab_type": "code",
        "outputId": "c9277ec9-264b-4a26-8f5b-4da27428b637",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer.texts_to_sequences([\"my father is so fat\", \"you are awesome himsik\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[6, 1185, 10, 19, 1116], [9, 40, 164]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvmyzwgJ38IC",
        "colab_type": "text"
      },
      "source": [
        "Comprobamos como tras tokenizar, solo usaremos max_features palabras distintas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcPRf5Tb38IC",
        "colab_type": "code",
        "outputId": "faac6e01-4603-4fdd-ee83-08e65e895041",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_tweets_tokenized = tokenizer.texts_to_sequences(df_train.sentence)\n",
        "len(set([word_id for tweet in train_tweets_tokenized for word_id in tweet]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASZCfeEm38IE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = sequence.pad_sequences(tokenizer.texts_to_sequences(df_train.sentence), maxlen=maxlen)\n",
        "y_train = df_train.label.values\n",
        "x_val = sequence.pad_sequences(tokenizer.texts_to_sequences(df_val.sentence), maxlen=maxlen)\n",
        "y_val = df_val.label.values\n",
        "x_test = sequence.pad_sequences(tokenizer.texts_to_sequences(df_test.sentence), maxlen=maxlen)\n",
        "y_test = df_test.label.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kB6Lolxx38IG",
        "colab_type": "text"
      },
      "source": [
        "## Creamos y entrenamos el modelo LSTM bidireccional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJHTH4bu38IH",
        "colab_type": "text"
      },
      "source": [
        "Construimos el modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxF7W0sp38IH",
        "colab_type": "code",
        "outputId": "3dd797c1-322d-4b74-f30c-2afd78b3b060",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Build model...')\n",
        "model_LSTM_Bi = Sequential()\n",
        "model_LSTM_Bi.add(Embedding(max_features, 128, input_length=maxlen))\n",
        "model_LSTM_Bi.add(Bidirectional(LSTM(64)))\n",
        "model_LSTM_Bi.add(Dropout(0.5))\n",
        "model_LSTM_Bi.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# try using different optimizers and different optimizer configs\n",
        "#De BERT\n",
        "#loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "#metric = tf.keras.metrics.SparseCategoricalAccuracy(\"accuracy\")\n",
        "#model.compile(optimizer=opt, loss=loss, metrics=[metric])\n",
        "\n",
        "#De BERT adaptado\n",
        "#loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "#metric = tf.keras.metrics.SparseCategoricalAccuracy(\"accuracy\")\n",
        "#model_LSTM_Bi.compile(optimizer = 'adam', loss=loss, metrics=[metric])\n",
        "\n",
        "#Original de esta LSTM\n",
        "model_LSTM_Bi.compile('adam', 'binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQ0ORsRg38IM",
        "colab_type": "text"
      },
      "source": [
        "Definimos las callbacks y entrenamos el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESrxjNUH38IM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_path = \"/content/drive/My Drive/\"\n",
        "#checkpoint_path = \"./\"\n",
        "\n",
        "class TimeHistory(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.times = []\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        self.epoch_time_start = time.time()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.times.append(time.time() - self.epoch_time_start)\n",
        "\n",
        "time_callback = TimeHistory()\n",
        "\n",
        "my_callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path + 'my_best_model_LSTM_Bi.{epoch:02d}-{val_accuracy:.2f}.h5', \n",
        "    verbose=1, save_best_only=True, save_weights_only=False, monitor = 'val_accuracy', mode = 'max'), \n",
        "    time_callback\n",
        "  ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9sTCsGD38IO",
        "colab_type": "code",
        "outputId": "df45d977-e21e-4ee6-c335-79a957e87b45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "print('Train...')\n",
        "history = model_LSTM_Bi.fit(x_train, y_train,\n",
        "                            batch_size=batch_size,\n",
        "                            epochs=epochs,\n",
        "                            validation_data=(x_val, y_val),\n",
        "                            verbose = 1,\n",
        "                            callbacks=my_callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train...\n",
            "Epoch 1/8\n",
            "42666/42667 [============================>.] - ETA: 0s - loss: 0.4069 - accuracy: 0.8149\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.82980, saving model to /content/drive/My Drive/my_best_model_LSTM_Bi.01-0.83.h5\n",
            "42667/42667 [==============================] - 1569s 37ms/step - loss: 0.4069 - accuracy: 0.8149 - val_loss: 0.3782 - val_accuracy: 0.8298\n",
            "Epoch 2/8\n",
            "42666/42667 [============================>.] - ETA: 0s - loss: 0.3613 - accuracy: 0.8408\n",
            "Epoch 00002: val_accuracy improved from 0.82980 to 0.83464, saving model to /content/drive/My Drive/my_best_model_LSTM_Bi.02-0.83.h5\n",
            "42667/42667 [==============================] - 1560s 37ms/step - loss: 0.3613 - accuracy: 0.8408 - val_loss: 0.3711 - val_accuracy: 0.8346\n",
            "Epoch 3/8\n",
            "42667/42667 [==============================] - ETA: 0s - loss: 0.3371 - accuracy: 0.8537\n",
            "Epoch 00003: val_accuracy did not improve from 0.83464\n",
            "42667/42667 [==============================] - 1556s 36ms/step - loss: 0.3371 - accuracy: 0.8537 - val_loss: 0.3763 - val_accuracy: 0.8311\n",
            "Epoch 4/8\n",
            "42666/42667 [============================>.] - ETA: 0s - loss: 0.3168 - accuracy: 0.8639\n",
            "Epoch 00004: val_accuracy did not improve from 0.83464\n",
            "42667/42667 [==============================] - 1543s 36ms/step - loss: 0.3168 - accuracy: 0.8639 - val_loss: 0.3824 - val_accuracy: 0.8320\n",
            "Epoch 5/8\n",
            "42666/42667 [============================>.] - ETA: 0s - loss: 0.2993 - accuracy: 0.8729\n",
            "Epoch 00005: val_accuracy did not improve from 0.83464\n",
            "42667/42667 [==============================] - 1543s 36ms/step - loss: 0.2993 - accuracy: 0.8729 - val_loss: 0.3885 - val_accuracy: 0.8296\n",
            "Epoch 6/8\n",
            "42666/42667 [============================>.] - ETA: 0s - loss: 0.2838 - accuracy: 0.8802\n",
            "Epoch 00006: val_accuracy did not improve from 0.83464\n",
            "42667/42667 [==============================] - 1546s 36ms/step - loss: 0.2838 - accuracy: 0.8802 - val_loss: 0.3997 - val_accuracy: 0.8281\n",
            "Epoch 7/8\n",
            "42667/42667 [==============================] - ETA: 0s - loss: 0.2708 - accuracy: 0.8863\n",
            "Epoch 00007: val_accuracy did not improve from 0.83464\n",
            "42667/42667 [==============================] - 1557s 36ms/step - loss: 0.2708 - accuracy: 0.8863 - val_loss: 0.4153 - val_accuracy: 0.8253\n",
            "Epoch 8/8\n",
            "42666/42667 [============================>.] - ETA: 0s - loss: 0.2601 - accuracy: 0.8912\n",
            "Epoch 00008: val_accuracy did not improve from 0.83464\n",
            "42667/42667 [==============================] - 1565s 37ms/step - loss: 0.2601 - accuracy: 0.8912 - val_loss: 0.4188 - val_accuracy: 0.8237\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8it0BBf38IQ",
        "colab_type": "text"
      },
      "source": [
        "Lo evaluamos en el conjunto test:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFKZV3oq38IQ",
        "colab_type": "code",
        "outputId": "3473cea0-eda0-4ec7-c864-1f88302f9cb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "loss, acc = model_LSTM_Bi.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "print('Test loss:', loss)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5334/5334 [==============================] - 19s 3ms/step - loss: 0.4177 - accuracy: 0.8238\n",
            "Test loss: 0.4176775813102722\n",
            "Test accuracy: 0.8237937688827515\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4lGT8rK38IS",
        "colab_type": "text"
      },
      "source": [
        "Guardamos el modelo y los datos que hemos ido recopilando durante el entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1UgID_e38IT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_LSTM_Bi.save(checkpoint_path + 'final_model_LSTM-Bi.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR5FoHUT38IU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert the history.history dict to a pandas DataFrame:     \n",
        "hist_df = pd.DataFrame(history.history) \n",
        "\n",
        "\n",
        "# save to csv: \n",
        "hist_csv_file = checkpoint_path + 'history_LSTM-Bi.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUohuH1X38IW",
        "colab_type": "code",
        "outputId": "8b179036-9c6e-4e6c-d8d4-4a8ffe4f457d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "time_callback.times"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1577.6120159626007,\n",
              " 1560.1105046272278,\n",
              " 1555.884030342102,\n",
              " 1543.2897021770477,\n",
              " 1542.7007710933685,\n",
              " 1546.0045628547668,\n",
              " 1557.3562870025635,\n",
              " 1564.6166729927063]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuIMnL3l38IY",
        "colab_type": "code",
        "outputId": "397e9387-bfd5-459b-e98a-e295f4b8cfa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "hist_df[\"times\"] = time_callback.times\n",
        "hist_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>times</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.406861</td>\n",
              "      <td>0.814927</td>\n",
              "      <td>0.378229</td>\n",
              "      <td>0.829800</td>\n",
              "      <td>1577.612016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.361261</td>\n",
              "      <td>0.840847</td>\n",
              "      <td>0.371101</td>\n",
              "      <td>0.834638</td>\n",
              "      <td>1560.110505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.337109</td>\n",
              "      <td>0.853740</td>\n",
              "      <td>0.376348</td>\n",
              "      <td>0.831100</td>\n",
              "      <td>1555.884030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.316792</td>\n",
              "      <td>0.863922</td>\n",
              "      <td>0.382415</td>\n",
              "      <td>0.831975</td>\n",
              "      <td>1543.289702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.299333</td>\n",
              "      <td>0.872939</td>\n",
              "      <td>0.388498</td>\n",
              "      <td>0.829550</td>\n",
              "      <td>1542.700771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.283780</td>\n",
              "      <td>0.880177</td>\n",
              "      <td>0.399679</td>\n",
              "      <td>0.828150</td>\n",
              "      <td>1546.004563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.270821</td>\n",
              "      <td>0.886291</td>\n",
              "      <td>0.415312</td>\n",
              "      <td>0.825262</td>\n",
              "      <td>1557.356287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.260113</td>\n",
              "      <td>0.891230</td>\n",
              "      <td>0.418778</td>\n",
              "      <td>0.823706</td>\n",
              "      <td>1564.616673</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       loss  accuracy  val_loss  val_accuracy        times\n",
              "0  0.406861  0.814927  0.378229      0.829800  1577.612016\n",
              "1  0.361261  0.840847  0.371101      0.834638  1560.110505\n",
              "2  0.337109  0.853740  0.376348      0.831100  1555.884030\n",
              "3  0.316792  0.863922  0.382415      0.831975  1543.289702\n",
              "4  0.299333  0.872939  0.388498      0.829550  1542.700771\n",
              "5  0.283780  0.880177  0.399679      0.828150  1546.004563\n",
              "6  0.270821  0.886291  0.415312      0.825262  1557.356287\n",
              "7  0.260113  0.891230  0.418778      0.823706  1564.616673"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxuqN3K938Ia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save to csv: \n",
        "hist_csv_file = checkpoint_path + 'history_LSTM_Bi_with_times.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_SsX5Y4gJPt",
        "colab_type": "text"
      },
      "source": [
        "Usamos el modelo para predecir la etiqueta de la frase \"i hate you\". Comprobamos que la salida se acerca bastante a 0, lo cual tiene sentido pues este comentario es bastante negativo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HckiFEQBdOP4",
        "colab_type": "code",
        "outputId": "87c43642-76d7-43db-f1d8-838362c4b8a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_LSTM_Bi.predict(sequence.pad_sequences(tokenizer.texts_to_sequences([\"i hate you\"]), maxlen=maxlen))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.05828063]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gf-G7LCg38Ic",
        "colab_type": "text"
      },
      "source": [
        "## Creamos y entrenamos el modelo LSTM-CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpYqX1bz38Ic",
        "colab_type": "text"
      },
      "source": [
        "Construimos el modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTZOHYzw38Id",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path + 'my_best_model_LSTM-CNN.{epoch:02d}-{val_accuracy:.2f}.h5', \n",
        "    verbose=1, save_best_only=True, save_weights_only=False, monitor = 'val_accuracy', mode = 'max'), \n",
        "    time_callback\n",
        "  ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qx9w1eHb38If",
        "colab_type": "code",
        "outputId": "15078818-9093-49d1-dece-b1ac9bf715f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Build model...')\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, embedding_size, input_length=maxlen)) #max_features en vez de vocab_size\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv1D(filters,\n",
        "                 kernel_size,\n",
        "                 padding='valid',\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "model.add(MaxPooling1D(pool_size=pool_size))\n",
        "model.add(LSTM(lstm_output_size))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OBicmSW38Ih",
        "colab_type": "text"
      },
      "source": [
        "Entrenamos el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUGy_Wh638Ih",
        "colab_type": "code",
        "outputId": "b9668901-aa06-4b91-d763-9ccade0aa7c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "print('Train...')\n",
        "history = model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_val, y_val),\n",
        "              verbose = 1,\n",
        "              callbacks=my_callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train...\n",
            "Epoch 1/8\n",
            "42666/42667 [============================>.] - ETA: 0s - loss: 0.4067 - accuracy: 0.8135\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.82799, saving model to /content/drive/My Drive/my_best_model_LSTM-CNN.01-0.83.h5\n",
            "42667/42667 [==============================] - 1302s 31ms/step - loss: 0.4067 - accuracy: 0.8135 - val_loss: 0.3824 - val_accuracy: 0.8280\n",
            "Epoch 2/8\n",
            "42667/42667 [==============================] - ETA: 0s - loss: 0.3655 - accuracy: 0.8373\n",
            "Epoch 00002: val_accuracy improved from 0.82799 to 0.83097, saving model to /content/drive/My Drive/my_best_model_LSTM-CNN.02-0.83.h5\n",
            "42667/42667 [==============================] - 1414s 33ms/step - loss: 0.3655 - accuracy: 0.8373 - val_loss: 0.3789 - val_accuracy: 0.8310\n",
            "Epoch 3/8\n",
            "42667/42667 [==============================] - ETA: 0s - loss: 0.3462 - accuracy: 0.8480\n",
            "Epoch 00003: val_accuracy improved from 0.83097 to 0.83266, saving model to /content/drive/My Drive/my_best_model_LSTM-CNN.03-0.83.h5\n",
            "42667/42667 [==============================] - 1439s 34ms/step - loss: 0.3462 - accuracy: 0.8480 - val_loss: 0.3782 - val_accuracy: 0.8327\n",
            "Epoch 4/8\n",
            "42666/42667 [============================>.] - ETA: 0s - loss: 0.3321 - accuracy: 0.8553\n",
            "Epoch 00004: val_accuracy did not improve from 0.83266\n",
            "42667/42667 [==============================] - 1444s 34ms/step - loss: 0.3321 - accuracy: 0.8553 - val_loss: 0.3812 - val_accuracy: 0.8320\n",
            "Epoch 5/8\n",
            "42666/42667 [============================>.] - ETA: 0s - loss: 0.3203 - accuracy: 0.8619\n",
            "Epoch 00005: val_accuracy did not improve from 0.83266\n",
            "42667/42667 [==============================] - 1437s 34ms/step - loss: 0.3203 - accuracy: 0.8619 - val_loss: 0.3902 - val_accuracy: 0.8307\n",
            "Epoch 6/8\n",
            "42666/42667 [============================>.] - ETA: 0s - loss: 0.3104 - accuracy: 0.8672\n",
            "Epoch 00006: val_accuracy did not improve from 0.83266\n",
            "42667/42667 [==============================] - 1440s 34ms/step - loss: 0.3104 - accuracy: 0.8672 - val_loss: 0.3941 - val_accuracy: 0.8309\n",
            "Epoch 7/8\n",
            "42666/42667 [============================>.] - ETA: 0s - loss: 0.3024 - accuracy: 0.8712\n",
            "Epoch 00007: val_accuracy did not improve from 0.83266\n",
            "42667/42667 [==============================] - 1438s 34ms/step - loss: 0.3024 - accuracy: 0.8712 - val_loss: 0.4039 - val_accuracy: 0.8280\n",
            "Epoch 8/8\n",
            "42666/42667 [============================>.] - ETA: 0s - loss: 0.2946 - accuracy: 0.8750\n",
            "Epoch 00008: val_accuracy did not improve from 0.83266\n",
            "42667/42667 [==============================] - 1443s 34ms/step - loss: 0.2946 - accuracy: 0.8750 - val_loss: 0.3961 - val_accuracy: 0.8292\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p14l1SUl38Ij",
        "colab_type": "text"
      },
      "source": [
        "Lo evaluamos en el conjunto test:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sViHztyd38Ik",
        "colab_type": "code",
        "outputId": "fb6c3613-106b-4cbe-865a-a2c4b086f3c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "loss, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "print('Test loss:', loss)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5334/5334 [==============================] - 13s 3ms/step - loss: 0.3950 - accuracy: 0.8288\n",
            "Test loss: 0.394981324672699\n",
            "Test accuracy: 0.828781247138977\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRo4XPuu38Im",
        "colab_type": "text"
      },
      "source": [
        "Guardamos el modelo y los datos que hemos ido recopilando durante el entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTS97jg438In",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(checkpoint_path + './final_model_LSTM-CNN.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzOm6E-v38Ip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert the history.history dict to a pandas DataFrame:     \n",
        "hist_df = pd.DataFrame(history.history) \n",
        "\n",
        "\n",
        "# or save to csv: \n",
        "hist_csv_file = checkpoint_path + 'history_LSTM-CNN.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya8SZXGt38Is",
        "colab_type": "code",
        "outputId": "209443ce-f53b-4444-ac00-d32051b0be7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "time_callback.times"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1303.345401763916,\n",
              " 1413.941558599472,\n",
              " 1439.3113844394684,\n",
              " 1443.7997148036957,\n",
              " 1437.3164551258087,\n",
              " 1440.3495645523071,\n",
              " 1438.215805053711,\n",
              " 1442.5869722366333]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35arwRY138Iu",
        "colab_type": "code",
        "outputId": "c5355b8f-255f-4580-f2e3-7da1c0c48b5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "hist_df[\"times\"] = time_callback.times\n",
        "hist_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>times</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.406653</td>\n",
              "      <td>0.813486</td>\n",
              "      <td>0.382395</td>\n",
              "      <td>0.827987</td>\n",
              "      <td>1303.345402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.365472</td>\n",
              "      <td>0.837310</td>\n",
              "      <td>0.378867</td>\n",
              "      <td>0.830975</td>\n",
              "      <td>1413.941559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.346212</td>\n",
              "      <td>0.847987</td>\n",
              "      <td>0.378166</td>\n",
              "      <td>0.832656</td>\n",
              "      <td>1439.311384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.332062</td>\n",
              "      <td>0.855298</td>\n",
              "      <td>0.381204</td>\n",
              "      <td>0.831975</td>\n",
              "      <td>1443.799715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.320304</td>\n",
              "      <td>0.861888</td>\n",
              "      <td>0.390198</td>\n",
              "      <td>0.830712</td>\n",
              "      <td>1437.316455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.310390</td>\n",
              "      <td>0.867178</td>\n",
              "      <td>0.394126</td>\n",
              "      <td>0.830863</td>\n",
              "      <td>1440.349565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.302358</td>\n",
              "      <td>0.871159</td>\n",
              "      <td>0.403873</td>\n",
              "      <td>0.828013</td>\n",
              "      <td>1438.215805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.294555</td>\n",
              "      <td>0.875039</td>\n",
              "      <td>0.396077</td>\n",
              "      <td>0.829206</td>\n",
              "      <td>1442.586972</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       loss  accuracy  val_loss  val_accuracy        times\n",
              "0  0.406653  0.813486  0.382395      0.827987  1303.345402\n",
              "1  0.365472  0.837310  0.378867      0.830975  1413.941559\n",
              "2  0.346212  0.847987  0.378166      0.832656  1439.311384\n",
              "3  0.332062  0.855298  0.381204      0.831975  1443.799715\n",
              "4  0.320304  0.861888  0.390198      0.830712  1437.316455\n",
              "5  0.310390  0.867178  0.394126      0.830863  1440.349565\n",
              "6  0.302358  0.871159  0.403873      0.828013  1438.215805\n",
              "7  0.294555  0.875039  0.396077      0.829206  1442.586972"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XKltrLJ38Iy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save to csv: \n",
        "hist_csv_file = checkpoint_path + 'history_LSTM-CNN_with_times.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}